{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1051f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# relevant only for this notebook\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import MLUtils.evaluation.Training as Training\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251b5d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris(as_frame=True)\n",
    "iris_df = iris.frame\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da73eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = iris_df.drop(columns='target')\n",
    "label_df = iris_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ce213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X_train, X_test, y_train, y_test, train_groups = Training.split_train_test(iris_df, label_column='target', splitter=KFold(), groups=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3767c55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
       " 'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
       " 'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training.LOGISTIC_REGRESSION_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ddd408",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best params\n",
      "{'C': 1e-05, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "--------------------------------------------------\n",
      "Train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       0.98      0.98      0.98        50\n",
      "           2       0.98      0.98      0.98        50\n",
      "\n",
      "    accuracy                           0.98       120\n",
      "   macro avg       0.99      0.99      0.99       120\n",
      "weighted avg       0.98      0.98      0.98       120\n",
      "\n",
      "--------------------------------------------------\n",
      "Test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "240 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.75       0.76666667        nan        nan        nan 0.03333333\n",
      " 0.01666667 0.01666667 0.01666667        nan        nan        nan\n",
      " 0.75       0.76666667        nan        nan        nan 0.03333333\n",
      " 0.01666667 0.01666667 0.01666667        nan        nan        nan\n",
      " 0.75       0.76666667        nan        nan        nan 0.03333333\n",
      " 0.01666667 0.01666667 0.01666667        nan        nan        nan\n",
      " 0.75       0.76666667        nan        nan        nan 0.05\n",
      " 0.08333333 0.08333333 0.01666667        nan        nan        nan\n",
      " 0.75       0.76666667        nan        nan        nan 0.01666667\n",
      " 0.58333333 0.58333333 0.09166667        nan        nan        nan\n",
      " 0.75       0.76666667        nan        nan        nan 0.66666667\n",
      " 0.74166667 0.74166667 0.6               nan        nan        nan\n",
      " 0.75       0.76666667        nan        nan        nan 0.75\n",
      " 0.75       0.75       0.73333333        nan        nan        nan\n",
      " 0.75       0.76666667        nan        nan        nan 0.74166667\n",
      " 0.75833333 0.75833333 0.75              nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\iefrati\\Anaconda3\\envs\\mlutils\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Training.eval_grid_search(LogisticRegression(), Training.LOGISTIC_REGRESSION_PARAMS, X_train, X_test, y_train, y_test, KFold())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27857129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100, 200, 500, 1000],\n",
       " 'max_features': ['auto', 'sqrt', 'log2'],\n",
       " 'max_depth': [4, 6, 8, 10, 12],\n",
       " 'criterion': ['gini', 'entropy']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training.RANDOM_FOREST_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a35b8e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Best params\n",
      "{'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 200}\n",
      "--------------------------------------------------\n",
      "Train classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      "--------------------------------------------------\n",
      "Test classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 6, 8, 10, 12],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [100, 200, 500, 1000]},\n",
       "             verbose=4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Training.eval_grid_search(RandomForestClassifier(), Training.RANDOM_FOREST_PARAMS, X_train, X_test, y_train, y_test, KFold())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLUtils]",
   "language": "python",
   "name": "conda-env-MLUtils-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
